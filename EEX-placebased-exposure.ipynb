{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7097e3ba",
   "metadata": {},
   "source": [
    "# Exploration of chemical pollutation from a place based perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ffad93",
   "metadata": {},
   "source": [
    "{bdg-link-info}`Notebook Repository <https://github.com/NERC-CEH/ds-toolbox-notebook-EEX-placebased-exposure.git>`\n",
    "{bdg-warning-line}`Ongoing Development`\n",
    "![alt text](./images/ukceh-logo-badge.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91660853",
   "metadata": {},
   "source": [
    "Primary Contact: [Dr. Michael Hollaway](https://www.ceh.ac.uk/staff/michael-hollaway)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8938b2dd",
   "metadata": {},
   "source": [
    "````{card} Challenge:\n",
    "When thinking about a particular place (E.g. a particular point, town, city or even a region), people often want to know more about the levels of pollution in that region in the present and often the past. This presents a significant challenge as there are multiple sources of pollutions (e.g. air pollution or water pollution) and multiple providers/collectors of pollution data (e.g. the Environment Agency (EA) or the Department for Environment, Food and Rural Affairs (Defra)). In addition there are ever increasing volumes of data being collected from a variety of sensor types. If someone wants to answer the question of \"I lived in the North East of England from 2000 to 2025, what sort of pollution was I exposed to?\" a significant challenges is presented to extract, fileter, aggregate and visualised the data in a meaningful way. The resultant workflow often requires different tools and technical skills to be able to answer the question. \n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff8b7a",
   "metadata": {},
   "source": [
    "````{card} Approach:\n",
    "This notebook presents a demonstration of one potential approach to addressing this challenge using examples of data from the Defra managed Automatic Urban and Rural Network ([AURN] (https://uk-air.defra.gov.uk/networks/network-info?view=aurn)) and the EA managed Water quality Gas/Liquid Chromatography mass spectrometry ([GCMS/LCMS](https://www.data.gov.uk/dataset/0c63b33e-0e34-45bb-a779-16a8c3a4b3f7/water-quality-monitoring-data-gc-ms-and-lc-ms-semi-quantitative-screen)) datasets to represent air and water pollution respectively. Developed using the python coding language the code shows methods for choosing a particular place, extracting all the available data for that place, calculating the summary statistics for that region (including some simple data science methods to interpolate between measurement locations) and visualising the final results. Finally functiionality is provided to run the notebook as a dashboard allowing the user to interatively run the analysis over different places. \n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c6384c",
   "metadata": {},
   "source": [
    "```{admonition} Running the Notebook:\n",
    ":class: tip, dropdown\n",
    "To run the notebook it is advised to first clone the repository housing the notebook ('*git clone https://github.com/NERC-CEH/ds-toolbox-notebook-EEX-placebased-exposure.git*'). This will create a folder in the current directory called *ds-toolbox-notebook-EEX-placebased-exposure*, which holds all the relevant files including the notebook, environment file and relevant input data. The next step is to create a conda environment with the right packages installed using the clean yml file ('*conda env create -f environment_clean.yml*'), which creates the *EEX-placebased-exposure* environment that can be activated using '*conda activate EEX-placebased-exposure*'. At this point the user can either run code from the notebook in their preferred IDE or via the jupyter interface using the command '*jupyter notebook*'.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9437ba9",
   "metadata": {},
   "source": [
    "```{admonition} Generalisability:\n",
    ":class: note, dropdown\n",
    "The methods and processes demonstrated in this notebook should be transferable to other datasets beyond the air quality and water quality examples used here. These methods should be able to work with other point based datasets and the spatial filtering should work for other polygons. The workflow presented is designed to be a starter example for a potential method to investigate location specific chemical pollution and is setup to be easily built upon for more detailed analysis.   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769862de",
   "metadata": {},
   "source": [
    "```{admonition} Data Sources:\n",
    ":class: note, dropdown\n",
    "This notebook uses data from the following sources:\n",
    "\n",
    "### Air Quality Data: Automatic Urban and Rural Network (AURN) \n",
    "\n",
    "A description of the AURN network is available from the \\href{https://uk-air.defra.gov.uk/networks/network-info?view=aurn}{UK-AIR}\n",
    "website.The data are freely available to download and are provided by the Department for the Environment and Rural Affairs\n",
    "(Defra) under the following attribution statement:\n",
    "\n",
    "(C) Crown copyright 2021 Defra via uk-air.defra.gov.uk, licensed under the \\href{https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/}{Open Government Licence}.\n",
    "\n",
    "### Water Quality Data: Water quality monitoring data GC-MS and LC-MS semi-quantitative screen\n",
    "\n",
    "A description of the EA water quality GC-MS and LC-MS semi-quantitative screen data is available from the \\href{https://www.gov.uk/government/publications/water-quality-monitoring-data-gc-ms-and-lc-ms-semi-quantitative-screen}{data.gov.uk}\n",
    "\n",
    "This dataset is licensed under the \\href{https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/}{Open Government Licence}.\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74b49cc",
   "metadata": {},
   "source": [
    "```{admonition} Computational Demands\n",
    ":class: warning, dropdown\n",
    "It should be noted that whilst this notebook in its current form runs fairly quickly on a standard laptop computer, this is achieved by pre-processing the raw data files into parquet format and only demonstrating the functionality of the methods using fairly computationally light operations and on a relatively small dataset. Therefore the user should be aware that if they desire to bring in more complex or advanced analytical methods or larger datasets then the computational demand will likely increase and appropriate CPU/GPU time may be needed. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c41e4e7",
   "metadata": {},
   "source": [
    "```{contents}\n",
    ":local:\n",
    "```\n",
    "<!-- https://jupyterbook.org/en/stable/structure/configure.html -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a9e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import geoviews as gv\n",
    "import geopandas as gpd\n",
    "from cartopy import crs as ccrs\n",
    "import numpy as np\n",
    "from holoviews.streams import Selection1D\n",
    "import panel as pn\n",
    "from scipy.interpolate import Rbf, griddata\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the bokeh extensions.\n",
    "gv.extension('bokeh')\n",
    "hv.extension('bokeh')\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ec5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the location of the data.\n",
    "data_path = \"C:\\\\Users\\\\mhollaway\\\\Documents\\\\JNCC_SLI2_tool\\\\Test_data\\\\\"\n",
    "\n",
    "#Read in the NUTS regions - NUTS3 in this example.\n",
    "NUTS_gdf = gpd.read_file(data_path + 'NUTS_Level_1_January_2018_GCB_in_the_United_Kingdom_2022_-2753267915301604886.geojson')\n",
    "\n",
    "#Read in the pre-processed data.\n",
    "all_data       = pl.read_parquet(data_path + \"EEX_all_data.parquet\")\n",
    "Sites_info_gdf = gpd.read_parquet(data_path + \"Sites_info_gdf.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84648e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTS_plt = gv.Polygons(NUTS_gdf, vdims=['nuts118cd','nuts118nm']).opts(color='black', fill_alpha=0, projection=ccrs.PlateCarree(),width=600,height=1000, tools=['hover', 'tap'], active_tools=['tap'], shared_axes=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaae320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate a summary of the chemical data in a selected region. \n",
    "def calc_chem_summary(index):\n",
    "\n",
    "    #Check for empty index if no selection yet made.\n",
    "    if not index:\n",
    "        out_col_list = ['Pollutant', 'Min Concentration', 'Max Concentration', 'Mean Concentration',\n",
    "                        'Number of Sites', 'Measurement Category', 'Unit', 'Measurement Source',\n",
    "                        'Sample Type', 'Date of first measurement', 'Date of last measurement']\n",
    "        return hv.Table(pd.DataFrame(columns=out_col_list)).opts(width=1200, height=400)\n",
    "\n",
    "    #If we have an index pick the geometry for filtering.\n",
    "    selected_poly = NUTS_gdf.geometry.iloc[index[0]]\n",
    "\n",
    "    # Filter sites in a specific polygon - this will be picked up using the index from the selector.\n",
    "    Sites_in_poly = Sites_info_gdf['Site_ID'].loc[Sites_info_gdf.geometry.within(selected_poly)]\n",
    "\n",
    "    #If no chemicals for given site pass back empty table.\n",
    "    if Sites_in_poly.shape[0] == 0:\n",
    "        out_col_list = ['Pollutant', 'Min Concentration', 'Max Concentration', 'Mean Concentration',\n",
    "                        'Number of Sites', 'Measurement Category', 'Unit', 'Measurement Source',\n",
    "                        'Sample Type', 'Date of first measurement', 'Date of last measurement']\n",
    "        return hv.Table(pd.DataFrame(columns=out_col_list)).opts(width=1200, height=400)\n",
    "    else:\n",
    "\n",
    "        # Get the data.\n",
    "        curr_rgn_data = all_data.filter((pl.col('Site_ID').is_in(Sites_in_poly) == True) & (pl.col('Concentration') > 0.0))\n",
    "\n",
    "        #Get the required summary for the region.\n",
    "        summ_rgn_data = curr_rgn_data.group_by('Pollutant').agg([\n",
    "            pl.col('Concentration').min().alias('Min Concentration'),\n",
    "            pl.col('Concentration').max().alias('Max Concentration'),\n",
    "            pl.col('Concentration').mean().alias('Mean Concentration'),\n",
    "            pl.col('Site_ID').n_unique().alias('Number of Sites'),\n",
    "            pl.col('Measurement Category').unique().alias('Measurement Category'),\n",
    "            pl.col('Unit').unique().alias('Unit'),\n",
    "            pl.col('Source').unique().alias('Measurement Source'),\n",
    "            pl.col('Site_Type').unique().alias('Sample Type'),\n",
    "            pl.col('Date').min().alias('Date of first measurement'),\n",
    "            pl.col('Date').max().alias('Date of last measurement')])\n",
    "\n",
    "        #Format the correct output for columns where multiple categories are returned.\n",
    "        summ_rgn_data = summ_rgn_data.with_columns(pl.col('Unit').list.join(',').alias('Unit'),\n",
    "                                                   pl.col('Measurement Source').list.join(',').alias('Measurement Source'),\n",
    "                                                   pl.col('Sample Type').list.join(',').alias('Sample Type'))\n",
    "\n",
    "\n",
    "        #Return either as a holoviews table (if in a panel app) or a pandas dataframe (if in the notebook)\n",
    "        if pn.state.served == True:\n",
    "            summ_reg_table = hv.Table(summ_rgn_data.to_pandas()).opts(width=1200, height=400)\n",
    "        else:\n",
    "            summ_reg_table = summ_rgn_data.to_pandas()\n",
    "        \n",
    "        return summ_reg_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc2e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_chem_summary([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chem_sites(index, chem):\n",
    "\n",
    "    #If no selection made display nothing.\n",
    "    if not index:\n",
    "        return gv.Polygons([], label='Please select a polygon to view data').opts(width=800,height=400, shared_axes=False)\n",
    "\n",
    "    # If we have an index pick the geometry for filtering.\n",
    "    selected_poly = NUTS_gdf.geometry.iloc[index[0]]\n",
    "    Sites_in_poly = Sites_info_gdf[['Site_ID', 'geometry']].loc[Sites_info_gdf.geometry.within(selected_poly)]\n",
    "\n",
    "    # Get the data.\n",
    "    curr_rgn_data = all_data.filter(pl.col('Site_ID').is_in(Sites_in_poly['Site_ID']) == True).select(['Site_ID', 'Pollutant', 'Concentration','Measurement Category'])\n",
    "\n",
    "    #If no data for the selected chemical return nothing.\n",
    "    if curr_rgn_data.shape[0] == 0:\n",
    "        if pn.state.served == True:\n",
    "            return gv.Polygons([], label='No Data for selected chemical for this region.').opts(width=800,height=400, shared_axes=False)\n",
    "\n",
    "    #Run a check on data type to plot, for vet meds plot locations and heatmap by samples, if AQ plot spatial distribution based on measurements.\n",
    "    if curr_rgn_data.filter(pl.col('Pollutant') == chem).select('Measurement Category').unique().item() == 'Vet meds':\n",
    "\n",
    "        count_df = curr_rgn_data.filter(pl.col('Pollutant') == chem).group_by('Site_ID').agg([pl.col('Concentration').mean().alias('Mean_Concentration')])\n",
    "\n",
    "        curr_chem_pts = Sites_in_poly.merge(count_df.to_pandas(), on='Site_ID')\n",
    "\n",
    "        #Now create the map.\n",
    "        #If in panel app pass out interactive plot if in regular notebook pass out static plot.\n",
    "        if pn.state.served == True:\n",
    "\n",
    "            #Polygons first.\n",
    "            curr_poly_layer = gv.Polygons(selected_poly).opts(color='black', fill_alpha=0, line_width=2, projection=ccrs.PlateCarree()) #Fill alpha sets fill to transparent.!\n",
    "            #Create a heatmap of points based on number of samples.\n",
    "            curr_pts_layer  = gv.Points(curr_chem_pts, vdims=['Site_ID','Mean_Concentration']).opts(\n",
    "                                        size=10,\n",
    "                                        color='Mean_Concentration',\n",
    "                                        cmap='Viridis',\n",
    "                                        tools=['hover'],\n",
    "                                        width=600,\n",
    "                                        height=400,\n",
    "                                        title='Mean Concentration of ' + chem + '(2000-2025) for: ' + NUTS_gdf['nuts118nm'].iloc[index[0]]\n",
    "                                        )\n",
    "\n",
    "            #Create the combined plot and set the dimensions.\n",
    "            curr_chem_plot  = (curr_poly_layer * curr_pts_layer).opts(width=800,height=400, shared_axes=False)\n",
    "\n",
    "        else:\n",
    "\n",
    "            #Plot the data as a staic matplotlib plot if not in a panel app.        \n",
    "            fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "            #Polygon.\n",
    "            NUTS_gdf.iloc[[index[0]]].plot(ax=ax, facecolor='none', edgecolor='black')\n",
    "\n",
    "            # Overlay points\n",
    "            points = ax.scatter(curr_chem_pts.geometry.x, curr_chem_pts.geometry.y, c=curr_chem_pts.Mean_Concentration, cmap='viridis', s=50, edgecolor='black', label='Measurement Sites')\n",
    "            fig.colorbar(points, ax=ax, label='Mean Concentration')\n",
    "\n",
    "            # Add labels and legend\n",
    "            ax.set_xlabel('Longitude')\n",
    "            ax.set_ylabel('Latitude')\n",
    "\n",
    "            #Set the title.\n",
    "            ax.set_title('Mean Concentration of ' + chem + '(2000-2025) for: ' + NUTS_gdf['nuts118nm'].iloc[index[0]])\n",
    "\n",
    "            curr_chem_plot = fig\n",
    "\n",
    "\n",
    "\n",
    "    elif curr_rgn_data.filter(pl.col('Pollutant') == chem).select('Measurement Category').unique().item() == 'Air quality':\n",
    "\n",
    "        #Calculate the total exposure to the air pollutant.\n",
    "        total_exp_df  = curr_rgn_data.filter(pl.col('Pollutant') == chem).group_by('Site_ID').agg([pl.col('Concentration').mean().alias('Mean Exposure')])\n",
    "        curr_chem_pts = Sites_in_poly.merge(total_exp_df.to_pandas(), on='Site_ID')\n",
    "        #Filter on where we have data.\n",
    "        curr_chem_pts = curr_chem_pts.loc[(curr_chem_pts['Mean Exposure'] > 0.0) & (curr_chem_pts['Mean Exposure'].isnull() == False)]\n",
    "\n",
    "        # KDE heatmap\n",
    "        x = curr_chem_pts.geometry.x\n",
    "        y = curr_chem_pts.geometry.y\n",
    "        weights = curr_chem_pts['Mean Exposure'].values\n",
    "\n",
    "        # Grid over polygon bounds - this will be used to model the exposure across the region on.\n",
    "        xmin, ymin, xmax, ymax = selected_poly.bounds\n",
    "        xx, yy    = np.mgrid[xmin:xmax:100j, ymin:ymax:100j] #Meshgrid for modelling the KDE on\n",
    "\n",
    "        # Quick check to see if we have enough data to fit the interpolation - if not just pass out zeros.\n",
    "        if len(weights) >= 4:\n",
    "          density = griddata(np.column_stack([x,y]), weights, (xx, yy), method='linear')\n",
    "        else:\n",
    "          density = np.zeros(xx.shape)\n",
    "\n",
    "        #Depending on if running in a notebook render as either holoviews (panel app) or matplotlib (notebook).\n",
    "        if pn.state.served == True:\n",
    "\n",
    "            # Holoviews Image\n",
    "            AQ_heatmap = hv.QuadMesh((xx,yy,density)).opts(cmap='Viridis',alpha=0.6,tools=['hover'],line_color=None,line_width=1,\n",
    "                                                        width=600,\n",
    "                                                        height=400,title='Air pollutant exposure: ' + chem)\n",
    "\n",
    "            #Also add the locations of the sampling points for the current AQ pollutant.\n",
    "            curr_pts_layer = gv.Points(curr_chem_pts, vdims=['Site_ID']).opts(\n",
    "                size=10,\n",
    "                color='Black',\n",
    "                tools=['hover'],\n",
    "                width=600,\n",
    "                height=400,\n",
    "                title='Sample Density Heatmap'\n",
    "            )\n",
    "\n",
    "\n",
    "            #Polygon layer.\n",
    "            curr_poly_layer = gv.Polygons(selected_poly).opts(color='black', fill_alpha=0, line_width=2,projection=ccrs.PlateCarree())  # Fill alpha sets fill to transparent.!\n",
    "\n",
    "            #Produce the final plot.\n",
    "            curr_chem_plot = (curr_poly_layer * AQ_heatmap * curr_pts_layer).opts(width=600, height=400, shared_axes=False)\n",
    "\n",
    "        else:\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "            #Plot the data as a staic matplotlib plot if not in a panel app.\n",
    "            mesh = ax.pcolormesh(xx, yy, density, cmap='viridis', shading='auto')\n",
    "            fig.colorbar(mesh, ax=ax, label='Total Concentration')\n",
    "\n",
    "            #Polygon.\n",
    "            NUTS_gdf.iloc[[index[0]]].plot(ax=ax, facecolor='none', edgecolor='black')\n",
    "\n",
    "            # Overlay points\n",
    "            ax.scatter(curr_chem_pts.geometry.x, curr_chem_pts.geometry.y, color='black', s=50, edgecolor='black', label='Measurement Sites')\n",
    "\n",
    "            # Add labels and legend\n",
    "            ax.set_xlabel('Longitude')\n",
    "            ax.set_ylabel('Latitude')\n",
    "\n",
    "            #Set the title.\n",
    "            ax.set_title('Air pollutant exposure: ' + chem + ' for: ' + NUTS_gdf['nuts118nm'].iloc[index[0]])\n",
    "\n",
    "            curr_chem_plot = fig\n",
    "\n",
    "    return curr_chem_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba834506",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_chem_sites([0], 'no2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd4aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run this cell if in a panel app.\n",
    "if pn.state.served == True:\n",
    "\n",
    "    #Now set up the notebook to run interactively if served via panel.\n",
    "    #Create a selection stream - this will be used to pick up the chemical data for each region.\n",
    "    selection_summary = Selection1D(source=NUTS_plt)\n",
    "\n",
    "    #Create a panel widget that holds the list of available chemicals.\n",
    "    chem_options = pn.widgets.Select(name='List of Chemicals', options=[])\n",
    "\n",
    "    #Callback function to update the widget.\n",
    "    #Need to se watch to true here as panel is updating the widget.\n",
    "    @pn.depends(selection_summary.param.index, watch=True)\n",
    "    def update_chem_options(index):\n",
    "\n",
    "        if index:\n",
    "            selected_poly        = NUTS_gdf.geometry.iloc[index[0]]\n",
    "            Sites_in_poly        = Sites_info_gdf['Site_ID'].loc[Sites_info_gdf.geometry.within(selected_poly)]\n",
    "            if Sites_in_poly.shape[0] == 0:\n",
    "                chem_options.options = ['No Chemicals Found']\n",
    "                chem_options.value = 'No Chemicals Found'\n",
    "            else:\n",
    "                chem_options.options = all_data.filter(pl.col('Site_ID').is_in(Sites_in_poly) == True).get_column('Pollutant').unique().to_list()\n",
    "                chem_options.value   = all_data.filter(pl.col('Site_ID').is_in(Sites_in_poly) == True).get_column('Pollutant').unique().to_list()[0]\n",
    "        else:\n",
    "            chem_options.options = ['No Chemicals Found']\n",
    "            chem_options.value = 'No Chemicals Found'\n",
    "\n",
    "    #Now need to set up reactive versions of the above functions to work in panel.\n",
    "    chem_summary_reactive = pn.bind(calc_chem_summary, selection_summary.param.index)\n",
    "    chem_plot_reactive    = pn.bind(plot_chem_sites, selection_summary.param.index, chem_options.param.value)\n",
    "\n",
    "    #Create the panel layout and serve.\n",
    "    dashboard = pn.Row(pn.Column(NUTS_plt) , pn.Column(pn.panel(chem_summary_reactive), pn.panel(chem_options), pn.panel(chem_plot_reactive)))\n",
    "    dashboard.servable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc3907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
